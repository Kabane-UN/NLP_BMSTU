{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "4fc16365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def preprocess(text):\n",
    "    removed_html = re.sub(r'<.*?>', '', text)\n",
    "    removed_url = re.sub(r'https?://\\S+|www\\.\\S+', '', removed_html)\n",
    "    return removed_url.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "df = pd.read_csv(r\"IMDB Dataset.csv\")\n",
    "X, y = df[\"review\"].apply(preprocess).to_numpy(), df[\"sentiment\"].map({\"positive\": 1, \"negative\": 0}).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "2aece2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTfidfVectorizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "        max_features=None,\n",
    "    ):\n",
    "        self.token_pattern = token_pattern\n",
    "        self.max_features = max_features\n",
    "        self.vocabulary = None\n",
    "        self.idf = None\n",
    "\n",
    "    def _preprocess(self, texts):\n",
    "        processed_texts = []\n",
    "        for text in texts:\n",
    "            text = text.lower()\n",
    "            words = re.findall(self.token_pattern, text)\n",
    "            processed_texts.append(words)\n",
    "        return processed_texts\n",
    "\n",
    "    def _build_vocabulary(self, processed_texts):\n",
    "        doc_count = len(processed_texts)\n",
    "        word_doc_freq = defaultdict(int)\n",
    "        for words in processed_texts:\n",
    "            unique_words = set(words)\n",
    "            for word in unique_words:\n",
    "                word_doc_freq[word] += 1\n",
    "        words = list(word_doc_freq.keys())\n",
    "        if self.max_features is not None and len(words) > self.max_features:\n",
    "            words.sort(key=lambda word: word_doc_freq[word], reverse=True)\n",
    "            words = words[: self.max_features]\n",
    "        else:\n",
    "            words.sort()\n",
    "        self.vocabulary = {word: idx for idx, word in enumerate(words)}\n",
    "        self.idf = {\n",
    "            word: np.log((doc_count + 1) / (word_doc_freq[word] + 1)) + 1\n",
    "            for word in self.vocabulary.keys()\n",
    "        }\n",
    "\n",
    "    def _compute_tf(self, words):\n",
    "        total_words = len(words)\n",
    "        if total_words == 0:\n",
    "            return {}\n",
    "        word_freq = defaultdict(int)\n",
    "        for word in words:\n",
    "            word_freq[word] += 1\n",
    "        tf = {word: freq / total_words for word, freq in word_freq.items()}\n",
    "        return tf\n",
    "\n",
    "    def fit(self, texts):\n",
    "        processed_texts = self._preprocess(texts)\n",
    "        self._build_vocabulary(processed_texts)\n",
    "        return self\n",
    "\n",
    "    def transform(self, texts):\n",
    "        processed_texts = self._preprocess(texts)\n",
    "        n_docs = len(processed_texts)\n",
    "        n_features = len(self.vocabulary)\n",
    "        tfidf_matrix = np.zeros((n_docs, n_features))\n",
    "        for doc_idx, words in enumerate(processed_texts):\n",
    "            tf = self._compute_tf(words)\n",
    "            for word, tf_value in tf.items():\n",
    "                if word in self.vocabulary:\n",
    "                    word_idx = self.vocabulary[word]\n",
    "                    tfidf_matrix[doc_idx, word_idx] = tf_value * self.idf[word]\n",
    "        return tfidf_matrix\n",
    "\n",
    "    def fit_transform(self, texts):\n",
    "        return self.fit(texts).transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "46dabf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCountVectorizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=None,\n",
    "    ):\n",
    "        self.token_pattern = token_pattern\n",
    "        self.max_features = max_features\n",
    "        self.ngram_range = ngram_range\n",
    "        self.vocabulary = None\n",
    "\n",
    "    def _preprocess(self, texts):\n",
    "        processed_texts = []\n",
    "        for text in texts:\n",
    "            text = text.lower()\n",
    "            words = re.findall(self.token_pattern, text)\n",
    "            ngrams_list = []\n",
    "            for n in range(self.ngram_range[0], self.ngram_range[1] + 1):\n",
    "                for i in range(len(words) - n + 1):\n",
    "                    ngram = \"_\".join(words[i : i + n])\n",
    "                    ngrams_list.append(ngram)\n",
    "            processed_texts.append(ngrams_list)\n",
    "        return processed_texts\n",
    "\n",
    "    def _build_vocabulary(self, processed_texts):\n",
    "        word_doc_freq = defaultdict(int)\n",
    "        for words in processed_texts:\n",
    "            unique_words = set(words)\n",
    "            for word in unique_words:\n",
    "                word_doc_freq[word] += 1\n",
    "        words = list(word_doc_freq.keys())\n",
    "        words.sort(key=lambda word: word_doc_freq[word], reverse=True)\n",
    "        if self.max_features is not None and len(words) > self.max_features:\n",
    "            words = words[: self.max_features]\n",
    "        self.vocabulary = {word: idx for idx, word in enumerate(words)}\n",
    "\n",
    "    def fit(self, texts):\n",
    "        processed_texts = self._preprocess(texts)\n",
    "        self._build_vocabulary(processed_texts)\n",
    "        return self\n",
    "\n",
    "    def transform(self, texts):\n",
    "        processed_texts = self._preprocess(texts)\n",
    "        n_docs = len(processed_texts)\n",
    "        n_features = len(self.vocabulary)\n",
    "        count_matrix = np.zeros((n_docs, n_features))\n",
    "        for doc_idx, words in enumerate(processed_texts):\n",
    "            for word in words:\n",
    "                if word in self.vocabulary:\n",
    "                    word_idx = self.vocabulary[word]\n",
    "                    count_matrix[doc_idx, word_idx] += 1\n",
    "        return count_matrix\n",
    "\n",
    "    def fit_transform(self, texts):\n",
    "        return self.fit(texts).transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "27fe1eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 5000)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = MyCountVectorizer(token_pattern=r'\\b[a-zA-Z]+\\b', max_features=5000)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "6b550262",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStandardScaler:\n",
    "    def fit(self, X):\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        self.std = np.std(X, axis=0)\n",
    "        self.std[self.std == 0] = 1.0\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return (X - self.mean) / self.std\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "db67f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySVM:\n",
    "    def __init__(\n",
    "        self,\n",
    "        C=1.0,\n",
    "        n_iters=1000,\n",
    "        lr=0.01,\n",
    "        momentum=0.9,\n",
    "        gamma=0.8,\n",
    "        tol=1e-4,\n",
    "    ):\n",
    "        self.C = C\n",
    "        self.n_iters = n_iters\n",
    "        self.lr = lr\n",
    "        self.tol = tol\n",
    "        self.scaler = MyStandardScaler()\n",
    "        self.gamma = gamma\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def _lr_scheduler(self, epoch):\n",
    "        return self.lr * (self.gamma**epoch)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = self.scaler.fit_transform(X)\n",
    "        n_samples, n_features = X.shape\n",
    "        labels = np.where(y == 0, -1, 1)\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "        velocity_w = np.zeros_like(self.w)\n",
    "        velocity_b = 0.0\n",
    "        for epoch in range(self.n_iters):\n",
    "            margins = labels * (np.dot(X, self.w) + self.b)\n",
    "            support_vectors_indicator = (margins < 1).astype(float)\n",
    "            grad_w = (\n",
    "                self.w\n",
    "                - self.C * np.dot(support_vectors_indicator * labels, X) / n_samples\n",
    "            )\n",
    "            grad_b = -self.C * np.sum(support_vectors_indicator * labels) / n_samples\n",
    "            w_prev = self.w.copy()\n",
    "            b_prev = self.b\n",
    "            lr = self._lr_scheduler(epoch)\n",
    "            velocity_w = self.momentum * velocity_w + grad_w\n",
    "            velocity_b = self.momentum * velocity_b + grad_b\n",
    "            self.w -= lr * velocity_w\n",
    "            self.b -= lr * velocity_b\n",
    "\n",
    "            if (\n",
    "                np.linalg.norm(self.w - w_prev) < self.tol\n",
    "                and abs(self.b - b_prev) < self.tol\n",
    "            ):\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.scaler.transform(X)\n",
    "        approx = np.dot(X, self.w) + self.b\n",
    "        return np.where(approx >= 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "91b70575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89      5000\n",
      "           1       0.88      0.91      0.89      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_svm = MySVM(lr=0.1, momentum=0.8, gamma=0.8)\n",
    "my_svm.fit(X_train, y_train)\n",
    "pred_my_svm = my_svm.predict(X_test)\n",
    "print(classification_report(y_test, pred_my_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "62746222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      5000\n",
      "           1       0.87      0.87      0.87      5000\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sk_svm = LinearSVC()\n",
    "sk_svm.fit(X_train, y_train)\n",
    "pred_sk_svm = sk_svm.predict(X_test)\n",
    "print(classification_report(y_test, pred_sk_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "d39dbe12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.,  3.,  2., ...,  0.,  0.,  0.],\n",
       "       [ 7.,  4.,  4., ...,  0.,  0.,  0.],\n",
       "       [18.,  6.,  8., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [15.,  6.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 9.,  5.,  7., ...,  0.,  0.,  0.],\n",
       "       [ 2.,  1.,  3., ...,  0.,  0.,  0.]], shape=(10000, 5000))"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "a8c9b0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_svm.predict(vectorizer.transform([\"The movie is not good\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "217a752d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0,\n",
       " 'a': 1,\n",
       " 'and': 2,\n",
       " 'of': 3,\n",
       " 'to': 4,\n",
       " 'this': 5,\n",
       " 'is': 6,\n",
       " 'in': 7,\n",
       " 'it': 8,\n",
       " 'that': 9,\n",
       " 'i': 10,\n",
       " 'for': 11,\n",
       " 'but': 12,\n",
       " 'with': 13,\n",
       " 'of_the': 14,\n",
       " 'was': 15,\n",
       " 'as': 16,\n",
       " 'on': 17,\n",
       " 'movie': 18,\n",
       " 'not': 19,\n",
       " 'have': 20,\n",
       " 'be': 21,\n",
       " 'are': 22,\n",
       " 'one': 23,\n",
       " 'film': 24,\n",
       " 'in_the': 25,\n",
       " 'you': 26,\n",
       " 'at': 27,\n",
       " 'all': 28,\n",
       " 'an': 29,\n",
       " 'its': 30,\n",
       " 'by': 31,\n",
       " 'from': 32,\n",
       " 'like': 33,\n",
       " 'so': 34,\n",
       " 'who': 35,\n",
       " 'his': 36,\n",
       " 'out': 37,\n",
       " 'if': 38,\n",
       " 'just': 39,\n",
       " 'about': 40,\n",
       " 'they': 41,\n",
       " 'or': 42,\n",
       " 'has': 43,\n",
       " 'he': 44,\n",
       " 'some': 45,\n",
       " 'what': 46,\n",
       " 'good': 47,\n",
       " 'and_the': 48,\n",
       " 'there': 49,\n",
       " 'is_a': 50,\n",
       " 'more': 51,\n",
       " 'when': 52,\n",
       " 'this_movie': 53,\n",
       " 'very': 54,\n",
       " 'time': 55,\n",
       " 'even': 56,\n",
       " 'up': 57,\n",
       " 'to_be': 58,\n",
       " 'only': 59,\n",
       " 'to_the': 60,\n",
       " 'see': 61,\n",
       " 'would': 62,\n",
       " 'no': 63,\n",
       " 'my': 64,\n",
       " 'can': 65,\n",
       " 'really': 66,\n",
       " 'which': 67,\n",
       " 'had': 68,\n",
       " 'me': 69,\n",
       " 'story': 70,\n",
       " 'were': 71,\n",
       " 'than': 72,\n",
       " 'much': 73,\n",
       " 'their': 74,\n",
       " 'well': 75,\n",
       " 'this_is': 76,\n",
       " 'the_film': 77,\n",
       " 'this_film': 78,\n",
       " 'get': 79,\n",
       " 'other': 80,\n",
       " 'the_movie': 81,\n",
       " 'been': 82,\n",
       " 'do': 83,\n",
       " 'in_a': 84,\n",
       " 'on_the': 85,\n",
       " 'most': 86,\n",
       " 'it_is': 87,\n",
       " 'into': 88,\n",
       " 'also': 89,\n",
       " 'one_of': 90,\n",
       " 'will': 91,\n",
       " 'her': 92,\n",
       " 'how': 93,\n",
       " 'dont': 94,\n",
       " 'great': 95,\n",
       " 'because': 96,\n",
       " 'for_the': 97,\n",
       " 'first': 98,\n",
       " 'people': 99,\n",
       " 'made': 100,\n",
       " 'with_the': 101,\n",
       " 'make': 102,\n",
       " 'of_a': 103,\n",
       " 'it_was': 104,\n",
       " 'could': 105,\n",
       " 'bad': 106,\n",
       " 'way': 107,\n",
       " 'any': 108,\n",
       " 'after': 109,\n",
       " 'movies': 110,\n",
       " 'too': 111,\n",
       " 'them': 112,\n",
       " 'then': 113,\n",
       " 'is_the': 114,\n",
       " 'think': 115,\n",
       " 'we': 116,\n",
       " 'watch': 117,\n",
       " 'seen': 118,\n",
       " 'characters': 119,\n",
       " 'at_the': 120,\n",
       " 'acting': 121,\n",
       " 'as_a': 122,\n",
       " 'being': 123,\n",
       " 'many': 124,\n",
       " 'films': 125,\n",
       " 'never': 126,\n",
       " 'in_this': 127,\n",
       " 'him': 128,\n",
       " 'she': 129,\n",
       " 'with_a': 130,\n",
       " 'know': 131,\n",
       " 'from_the': 132,\n",
       " 'best': 133,\n",
       " 'plot': 134,\n",
       " 'ever': 135,\n",
       " 'two': 136,\n",
       " 'little': 137,\n",
       " 'where': 138,\n",
       " 'did': 139,\n",
       " 'character': 140,\n",
       " 'better': 141,\n",
       " 'does': 142,\n",
       " 'as_the': 143,\n",
       " 'love': 144,\n",
       " 'if_you': 145,\n",
       " 'say': 146,\n",
       " 'off': 147,\n",
       " 'to_see': 148,\n",
       " 'your': 149,\n",
       " 'out_of': 150,\n",
       " 'end': 151,\n",
       " 'still': 152,\n",
       " 'life': 153,\n",
       " 'that_the': 154,\n",
       " 'over': 155,\n",
       " 'i_was': 156,\n",
       " 'these': 157,\n",
       " 'should': 158,\n",
       " 'something': 159,\n",
       " 'go': 160,\n",
       " 'by_the': 161,\n",
       " 'for_a': 162,\n",
       " 'while': 163,\n",
       " 'such': 164,\n",
       " 'scenes': 165,\n",
       " 'the_story': 166,\n",
       " 'here': 167,\n",
       " 'through': 168,\n",
       " 'and_i': 169,\n",
       " 'scene': 170,\n",
       " 'those': 171,\n",
       " 'why': 172,\n",
       " 'was_a': 173,\n",
       " 'watching': 174,\n",
       " 'all_the': 175,\n",
       " 'movie_is': 176,\n",
       " 'of_this': 177,\n",
       " 'back': 178,\n",
       " 'thing': 179,\n",
       " 'i_have': 180,\n",
       " 'actors': 181,\n",
       " 'real': 182,\n",
       " 'im': 183,\n",
       " 'man': 184,\n",
       " 'and_a': 185,\n",
       " 'doesnt': 186,\n",
       " 'have_been': 187,\n",
       " 'didnt': 188,\n",
       " 'before': 189,\n",
       " 'years': 190,\n",
       " 'makes': 191,\n",
       " 'now': 192,\n",
       " 'another': 193,\n",
       " 'find': 194,\n",
       " 'actually': 195,\n",
       " 'the_first': 196,\n",
       " 'look': 197,\n",
       " 'though': 198,\n",
       " 'few': 199,\n",
       " 'going': 200,\n",
       " 'same': 201,\n",
       " 'nothing': 202,\n",
       " 'is_not': 203,\n",
       " 'there_is': 204,\n",
       " 'show': 205,\n",
       " 'every': 206,\n",
       " 'work': 207,\n",
       " 'lot': 208,\n",
       " 'film_is': 209,\n",
       " 'cant': 210,\n",
       " 'a_good': 211,\n",
       " 'want': 212,\n",
       " 'funny': 213,\n",
       " 'part': 214,\n",
       " 'the_same': 215,\n",
       " 'old': 216,\n",
       " 'the_end': 217,\n",
       " 'new': 218,\n",
       " 'again': 219,\n",
       " 'cast': 220,\n",
       " 'a_lot': 221,\n",
       " 'director': 222,\n",
       " 'thats': 223,\n",
       " 'but_the': 224,\n",
       " 'give': 225,\n",
       " 'things': 226,\n",
       " 'the_most': 227,\n",
       " 'down': 228,\n",
       " 'quite': 229,\n",
       " 'the_best': 230,\n",
       " 'take': 231,\n",
       " 'got': 232,\n",
       " 'around': 233,\n",
       " 'fact': 234,\n",
       " 'pretty': 235,\n",
       " 'enough': 236,\n",
       " 'there_are': 237,\n",
       " 'thought': 238,\n",
       " 'seems': 239,\n",
       " 'on_a': 240,\n",
       " 'to_make': 241,\n",
       " 'us': 242,\n",
       " 'but_i': 243,\n",
       " 'saw': 244,\n",
       " 'about_the': 245,\n",
       " 'come': 246,\n",
       " 'without': 247,\n",
       " 'both': 248,\n",
       " 'big': 249,\n",
       " 'however': 250,\n",
       " 'between': 251,\n",
       " 'long': 252,\n",
       " 'ive': 253,\n",
       " 'must': 254,\n",
       " 'times': 255,\n",
       " 'own': 256,\n",
       " 'may': 257,\n",
       " 'right': 258,\n",
       " 'that_is': 259,\n",
       " 'least': 260,\n",
       " 'a_movie': 261,\n",
       " 'always': 262,\n",
       " 'to_watch': 263,\n",
       " 'almost': 264,\n",
       " 'world': 265,\n",
       " 'whole': 266,\n",
       " 'young': 267,\n",
       " 'the_only': 268,\n",
       " 'gets': 269,\n",
       " 'isnt': 270,\n",
       " 'that_i': 271,\n",
       " 'that_it': 272,\n",
       " 'done': 273,\n",
       " 'be_a': 274,\n",
       " 'this_one': 275,\n",
       " 'a_great': 276,\n",
       " 'of_his': 277,\n",
       " 'but_it': 278,\n",
       " 'i_think': 279,\n",
       " 'to_a': 280,\n",
       " 'far': 281,\n",
       " 'interesting': 282,\n",
       " 'anything': 283,\n",
       " 'bit': 284,\n",
       " 'a_very': 285,\n",
       " 'point': 286,\n",
       " 'since': 287,\n",
       " 'the_characters': 288,\n",
       " 'the_plot': 289,\n",
       " 'feel': 290,\n",
       " 'last': 291,\n",
       " 'might': 292,\n",
       " 'was_the': 293,\n",
       " 'and_it': 294,\n",
       " 'script': 295,\n",
       " 'probably': 296,\n",
       " 'a_few': 297,\n",
       " 'role': 298,\n",
       " 'have_to': 299,\n",
       " 'to_get': 300,\n",
       " 'am': 301,\n",
       " 'music': 302,\n",
       " 'minutes': 303,\n",
       " 'some_of': 304,\n",
       " 'anyone': 305,\n",
       " 'away': 306,\n",
       " 'sure': 307,\n",
       " 'kind': 308,\n",
       " 'want_to': 309,\n",
       " 'is_that': 310,\n",
       " 'found': 311,\n",
       " 'comedy': 312,\n",
       " 'he_is': 313,\n",
       " 'i_dont': 314,\n",
       " 'worst': 315,\n",
       " 'making': 316,\n",
       " 'to_do': 317,\n",
       " 'original': 318,\n",
       " 'theres': 319,\n",
       " 'like_a': 320,\n",
       " 'yet': 321,\n",
       " 'performance': 322,\n",
       " 'believe': 323,\n",
       " 'its_a': 324,\n",
       " 'rather': 325,\n",
       " 'guy': 326,\n",
       " 'especially': 327,\n",
       " 'the_acting': 328,\n",
       " 'is_one': 329,\n",
       " 'a_little': 330,\n",
       " 'hard': 331,\n",
       " 'worth': 332,\n",
       " 'into_the': 333,\n",
       " 'at_least': 334,\n",
       " 'comes': 335,\n",
       " 'they_are': 336,\n",
       " 'lot_of': 337,\n",
       " 'the_other': 338,\n",
       " 'action': 339,\n",
       " 'trying': 340,\n",
       " 'would_have': 341,\n",
       " 'put': 342,\n",
       " 'the_way': 343,\n",
       " 'fun': 344,\n",
       " 'having': 345,\n",
       " 'has_a': 346,\n",
       " 'played': 347,\n",
       " 'goes': 348,\n",
       " 'course': 349,\n",
       " 'tv': 350,\n",
       " 'a_film': 351,\n",
       " 'each': 352,\n",
       " 'looking': 353,\n",
       " 'although': 354,\n",
       " 'have_a': 355,\n",
       " 'hes': 356,\n",
       " 'would_be': 357,\n",
       " 'watched': 358,\n",
       " 'horror': 359,\n",
       " 'everything': 360,\n",
       " 'to_have': 361,\n",
       " 'i_would': 362,\n",
       " 'once': 363,\n",
       " 'i_am': 364,\n",
       " 'shows': 365,\n",
       " 'that_this': 366,\n",
       " 'place': 367,\n",
       " 'kind_of': 368,\n",
       " 'family': 369,\n",
       " 'as_well': 370,\n",
       " 'day': 371,\n",
       " 'wasnt': 372,\n",
       " 'main': 373,\n",
       " 'reason': 374,\n",
       " 'different': 375,\n",
       " 'set': 376,\n",
       " 'trying_to': 377,\n",
       " 'like_the': 378,\n",
       " 'looks': 379,\n",
       " 'the_whole': 380,\n",
       " 'this_was': 381,\n",
       " 'screen': 382,\n",
       " 'ending': 383,\n",
       " 'girl': 384,\n",
       " 'maybe': 385,\n",
       " 'someone': 386,\n",
       " 'sense': 387,\n",
       " 'together': 388,\n",
       " 'is_an': 389,\n",
       " 'woman': 390,\n",
       " 'dvd': 391,\n",
       " 'instead': 392,\n",
       " 'said': 393,\n",
       " 'seem': 394,\n",
       " 'seeing': 395,\n",
       " 'takes': 396,\n",
       " 'true': 397,\n",
       " 'job': 398,\n",
       " 'movie_was': 399,\n",
       " 'everyone': 400,\n",
       " 'money': 401,\n",
       " 'during': 402,\n",
       " 'plays': 403,\n",
       " 'our': 404,\n",
       " 'most_of': 405,\n",
       " 'series': 406,\n",
       " 'you_can': 407,\n",
       " 'actor': 408,\n",
       " 'left': 409,\n",
       " 'not_a': 410,\n",
       " 'effects': 411,\n",
       " 'and_his': 412,\n",
       " 'in_his': 413,\n",
       " 'to_say': 414,\n",
       " 'the_worst': 415,\n",
       " 'a_bit': 416,\n",
       " 'later': 417,\n",
       " 'more_than': 418,\n",
       " 'of_course': 419,\n",
       " 'three': 420,\n",
       " 'which_is': 421,\n",
       " 'special': 422,\n",
       " 'excellent': 423,\n",
       " 'beautiful': 424,\n",
       " 'the_time': 425,\n",
       " 'himself': 426,\n",
       " 'i_can': 427,\n",
       " 'else': 428,\n",
       " 'play': 429,\n",
       " 'idea': 430,\n",
       " 'going_to': 431,\n",
       " 'used': 432,\n",
       " 'audience': 433,\n",
       " 'who_is': 434,\n",
       " 'at_all': 435,\n",
       " 'i_had': 436,\n",
       " 'by_a': 437,\n",
       " 'fan': 438,\n",
       " 'recommend': 439,\n",
       " 'high': 440,\n",
       " 'he_was': 441,\n",
       " 'night': 442,\n",
       " 'simply': 443,\n",
       " 'completely': 444,\n",
       " 'along': 445,\n",
       " 'i_saw': 446,\n",
       " 'that_he': 447,\n",
       " 'could_have': 448,\n",
       " 'mind': 449,\n",
       " 'shot': 450,\n",
       " 'of_all': 451,\n",
       " 'until': 452,\n",
       " 'use': 453,\n",
       " 'less': 454,\n",
       " 'try': 455,\n",
       " 'but_this': 456,\n",
       " 'rest': 457,\n",
       " 'nice': 458,\n",
       " 'when_i': 459,\n",
       " 'all_of': 460,\n",
       " 'need': 461,\n",
       " 'poor': 462,\n",
       " 'help': 463,\n",
       " 'youre': 464,\n",
       " 'second': 465,\n",
       " 'either': 466,\n",
       " 'american': 467,\n",
       " 'of_it': 468,\n",
       " 'into_a': 469,\n",
       " 'movie_and': 470,\n",
       " 'enjoy': 471,\n",
       " 'in_my': 472,\n",
       " 'read': 473,\n",
       " 'when_the': 474,\n",
       " 'friends': 475,\n",
       " 'performances': 476,\n",
       " 'given': 477,\n",
       " 'came': 478,\n",
       " 'part_of': 479,\n",
       " 'is_so': 480,\n",
       " 'movie_i': 481,\n",
       " 'such_a': 482,\n",
       " 'truly': 483,\n",
       " 'start': 484,\n",
       " 'of_them': 485,\n",
       " 'year': 486,\n",
       " 'seems_to': 487,\n",
       " 'short': 488,\n",
       " 'next': 489,\n",
       " 'john': 490,\n",
       " 'line': 491,\n",
       " 'for_this': 492,\n",
       " 'and_then': 493,\n",
       " 'classic': 494,\n",
       " 'let': 495,\n",
       " 'getting': 496,\n",
       " 'like_this': 497,\n",
       " 'wrong': 498,\n",
       " 'tell': 499,\n",
       " 'it_has': 500,\n",
       " 'film_and': 501,\n",
       " 'home': 502,\n",
       " 'others': 503,\n",
       " 'the_fact': 504,\n",
       " 'is_just': 505,\n",
       " 'couple': 506,\n",
       " 'half': 507,\n",
       " 'boring': 508,\n",
       " 'keep': 509,\n",
       " 'full': 510,\n",
       " 'production': 511,\n",
       " 'black': 512,\n",
       " 'you_have': 513,\n",
       " 'it_to': 514,\n",
       " 'i_thought': 515,\n",
       " 'death': 516,\n",
       " 'understand': 517,\n",
       " 'the_actors': 518,\n",
       " 'the_rest': 519,\n",
       " 'from_a': 520,\n",
       " 'its_not': 521,\n",
       " 'version': 522,\n",
       " 'star': 523,\n",
       " 'playing': 524,\n",
       " 'definitely': 525,\n",
       " 'as_it': 526,\n",
       " 'with_his': 527,\n",
       " 'remember': 528,\n",
       " 'itself': 529,\n",
       " 'hollywood': 530,\n",
       " 'doing': 531,\n",
       " 'couldnt': 532,\n",
       " 'went': 533,\n",
       " 'absolutely': 534,\n",
       " 'you_are': 535,\n",
       " 'wife': 536,\n",
       " 'over_the': 537,\n",
       " 'perhaps': 538,\n",
       " 'is_very': 539,\n",
       " 'fact_that': 540,\n",
       " 'small': 541,\n",
       " 'gives': 542,\n",
       " 'that_was': 543,\n",
       " 'the_main': 544,\n",
       " 'dead': 545,\n",
       " 'mean': 546,\n",
       " 'wonderful': 547,\n",
       " 'camera': 548,\n",
       " 'name': 549,\n",
       " 'moments': 550,\n",
       " 'the_world': 551,\n",
       " 'had_a': 552,\n",
       " 'be_the': 553,\n",
       " 'it_and': 554,\n",
       " 'through_the': 555,\n",
       " 'piece': 556,\n",
       " 'top': 557,\n",
       " 'early': 558,\n",
       " 'often': 559,\n",
       " 'has_been': 560,\n",
       " 'of_my': 561,\n",
       " 'they_were': 562,\n",
       " 'at_a': 563,\n",
       " 'certainly': 564,\n",
       " 'stupid': 565,\n",
       " 'awful': 566,\n",
       " 'men': 567,\n",
       " 'and_is': 568,\n",
       " 'see_the': 569,\n",
       " 'face': 570,\n",
       " 'stars': 571,\n",
       " 'lines': 572,\n",
       " 'terrible': 573,\n",
       " 'hope': 574,\n",
       " 'become': 575,\n",
       " 'case': 576,\n",
       " 'house': 577,\n",
       " 'so_much': 578,\n",
       " 'dialogue': 579,\n",
       " 'person': 580,\n",
       " 'book': 581,\n",
       " 'entire': 582,\n",
       " 'about_this': 583,\n",
       " 'liked': 584,\n",
       " 'kids': 585,\n",
       " 'written': 586,\n",
       " 'the_director': 587,\n",
       " 'that_they': 588,\n",
       " 'it_would': 589,\n",
       " 'entertaining': 590,\n",
       " 'perfect': 591,\n",
       " 'head': 592,\n",
       " 'the_original': 593,\n",
       " 'it_a': 594,\n",
       " 'loved': 595,\n",
       " 'sort': 596,\n",
       " 'finally': 597,\n",
       " 'felt': 598,\n",
       " 'beginning': 599,\n",
       " 'waste': 600,\n",
       " 'the_last': 601,\n",
       " 'budget': 602,\n",
       " 'can_be': 603,\n",
       " 'supposed': 604,\n",
       " 'there_was': 605,\n",
       " 'story_is': 606,\n",
       " 'movie_that': 607,\n",
       " 'will_be': 608,\n",
       " 'human': 609,\n",
       " 'the_script': 610,\n",
       " 'several': 611,\n",
       " 'live': 612,\n",
       " 'film_was': 613,\n",
       " 'wanted': 614,\n",
       " 'the_two': 615,\n",
       " 'to_find': 616,\n",
       " 'video': 617,\n",
       " 'laugh': 618,\n",
       " 'rest_of': 619,\n",
       " 'not_to': 620,\n",
       " 'lost': 621,\n",
       " 'with_this': 622,\n",
       " 'worse': 623,\n",
       " 'in_fact': 624,\n",
       " 'wont': 625,\n",
       " 'based': 626,\n",
       " 'school': 627,\n",
       " 'and_that': 628,\n",
       " 'she_is': 629,\n",
       " 'against': 630,\n",
       " 'already': 631,\n",
       " 'title': 632,\n",
       " 'and_its': 633,\n",
       " 'totally': 634,\n",
       " 'problem': 635,\n",
       " 'is_in': 636,\n",
       " 'style': 637,\n",
       " 'about_a': 638,\n",
       " 'to_this': 639,\n",
       " 'turn': 640,\n",
       " 'guess': 641,\n",
       " 'ever_seen': 642,\n",
       " 'women': 643,\n",
       " 'father': 644,\n",
       " 'direction': 645,\n",
       " 'because_of': 646,\n",
       " 'throughout': 647,\n",
       " 'example': 648,\n",
       " 'picture': 649,\n",
       " 'should_be': 650,\n",
       " 'film_that': 651,\n",
       " 'care': 652,\n",
       " 'lead': 653,\n",
       " 'guys': 654,\n",
       " 'just_a': 655,\n",
       " 'called': 656,\n",
       " 'yes': 657,\n",
       " 'able': 658,\n",
       " 'i_cant': 659,\n",
       " 'and_he': 660,\n",
       " 'watch_it': 661,\n",
       " 'does_not': 662,\n",
       " 'sort_of': 663,\n",
       " 'not_the': 664,\n",
       " 'becomes': 665,\n",
       " 'final': 666,\n",
       " 'to_go': 667,\n",
       " 'make_a': 668,\n",
       " 'sex': 669,\n",
       " 'than_the': 670,\n",
       " 'friend': 671,\n",
       " 'he_has': 672,\n",
       " 'war': 673,\n",
       " 'lives': 674,\n",
       " 'days': 675,\n",
       " 'watch_this': 676,\n",
       " 'i_could': 677,\n",
       " 'id': 678,\n",
       " 'acting_is': 679,\n",
       " 'youll': 680,\n",
       " 'fans': 681,\n",
       " 'sound': 682,\n",
       " 'the_cast': 683,\n",
       " 'is_no': 684,\n",
       " 'low': 685,\n",
       " 'seemed': 686,\n",
       " 'up_to': 687,\n",
       " 'able_to': 688,\n",
       " 'hard_to': 689,\n",
       " 'and_this': 690,\n",
       " 'gave': 691,\n",
       " 'as_i': 692,\n",
       " 'of_her': 693,\n",
       " 'is_also': 694,\n",
       " 'despite': 695,\n",
       " 'see_it': 696,\n",
       " 'has_to': 697,\n",
       " 'enjoyed': 698,\n",
       " 'i_didnt': 699,\n",
       " 'under': 700,\n",
       " 'it_i': 701,\n",
       " 'quality': 702,\n",
       " 'wants': 703,\n",
       " 'supposed_to': 704,\n",
       " 'had_to': 705,\n",
       " 'i_found': 706,\n",
       " 'and_not': 707,\n",
       " 'drama': 708,\n",
       " 'cinema': 709,\n",
       " 'you_will': 710,\n",
       " 'turns': 711,\n",
       " 'writing': 712,\n",
       " 'oh': 713,\n",
       " 'to_his': 714,\n",
       " 'fine': 715,\n",
       " 'dark': 716,\n",
       " 'see_this': 717,\n",
       " 'boy': 718,\n",
       " 'works': 719,\n",
       " 'unfortunately': 720,\n",
       " 'matter': 721,\n",
       " 'humor': 722,\n",
       " 'as_an': 723,\n",
       " 'because_it': 724,\n",
       " 'was_not': 725,\n",
       " 'where_the': 726,\n",
       " 'amazing': 727,\n",
       " 'that_you': 728,\n",
       " 'tries': 729,\n",
       " 'such_as': 730,\n",
       " 'of_those': 731,\n",
       " 'end_of': 732,\n",
       " 'on_this': 733,\n",
       " 'when_he': 734,\n",
       " 'so_i': 735,\n",
       " 'in_an': 736,\n",
       " 'behind': 737,\n",
       " 'enough_to': 738,\n",
       " 'have_seen': 739,\n",
       " 'up_with': 740,\n",
       " 'expect': 741,\n",
       " 'overall': 742,\n",
       " 'obviously': 743,\n",
       " 'say_that': 744,\n",
       " 'myself': 745,\n",
       " 'took': 746,\n",
       " 'after_the': 747,\n",
       " 'well_as': 748,\n",
       " 'are_a': 749,\n",
       " 'of_their': 750,\n",
       " 'parts': 751,\n",
       " 'thinking': 752,\n",
       " 'past': 753,\n",
       " 'heard': 754,\n",
       " 'ones': 755,\n",
       " 'act': 756,\n",
       " 'not_only': 757,\n",
       " 'but_its': 758,\n",
       " 'themselves': 759,\n",
       " 'do_not': 760,\n",
       " 'it_the': 761,\n",
       " 'of_an': 762,\n",
       " 'a_bad': 763,\n",
       " 'for_me': 764,\n",
       " 'favorite': 765,\n",
       " 'so_many': 766,\n",
       " 'are_the': 767,\n",
       " 'i_just': 768,\n",
       " 'should_have': 769,\n",
       " 'seem_to': 770,\n",
       " 'history': 771,\n",
       " 'run': 772,\n",
       " 'horrible': 773,\n",
       " 'better_than': 774,\n",
       " 'the_audience': 775,\n",
       " 'a_couple': 776,\n",
       " 'mother': 777,\n",
       " 'theyre': 778,\n",
       " 'film_i': 779,\n",
       " 'side': 780,\n",
       " 'eyes': 781,\n",
       " 'white': 782,\n",
       " 'highly': 783,\n",
       " 'very_good': 784,\n",
       " 'flick': 785,\n",
       " 'i_really': 786,\n",
       " 'directed': 787,\n",
       " 'when_it': 788,\n",
       " 'i_know': 789,\n",
       " 'stuff': 790,\n",
       " 'kill': 791,\n",
       " 'movie_the': 792,\n",
       " 'starts': 793,\n",
       " 'you_want': 794,\n",
       " 'shes': 795,\n",
       " 'in_it': 796,\n",
       " 'to_me': 797,\n",
       " 'except': 798,\n",
       " 'brilliant': 799,\n",
       " 'ill': 800,\n",
       " 'a_big': 801,\n",
       " 'wouldnt': 802,\n",
       " 'to_take': 803,\n",
       " 'evil': 804,\n",
       " 'late': 805,\n",
       " 'in_their': 806,\n",
       " 'the_ending': 807,\n",
       " 'during_the': 808,\n",
       " 'viewer': 809,\n",
       " 'soon': 810,\n",
       " 'sometimes': 811,\n",
       " 'leave': 812,\n",
       " 'coming': 813,\n",
       " 'happens': 814,\n",
       " 'about_it': 815,\n",
       " 'and_they': 816,\n",
       " 'in_which': 817,\n",
       " 'wonder': 818,\n",
       " 'decent': 819,\n",
       " 'in_all': 820,\n",
       " 'feeling': 821,\n",
       " 'involved': 822,\n",
       " 'what_the': 823,\n",
       " 'film_the': 824,\n",
       " 'children': 825,\n",
       " 'lack': 826,\n",
       " 'back_to': 827,\n",
       " 'ive_seen': 828,\n",
       " 'out_the': 829,\n",
       " 'based_on': 830,\n",
       " 'complete': 831,\n",
       " 'actress': 832,\n",
       " 'chance': 833,\n",
       " 'piece_of': 834,\n",
       " 'says': 835,\n",
       " 'heart': 836,\n",
       " 'taken': 837,\n",
       " 'extremely': 838,\n",
       " 'close': 839,\n",
       " 'the_films': 840,\n",
       " 'did_not': 841,\n",
       " 'the_entire': 842,\n",
       " 'hell': 843,\n",
       " 'killed': 844,\n",
       " 'group': 845,\n",
       " 'if_the': 846,\n",
       " 'the_one': 847,\n",
       " 'too_much': 848,\n",
       " 'genre': 849,\n",
       " 'are_not': 850,\n",
       " 'told': 851,\n",
       " 'story_of': 852,\n",
       " 'looked': 853,\n",
       " 'experience': 854,\n",
       " 'fan_of': 855,\n",
       " 'and_you': 856,\n",
       " 'including': 857,\n",
       " 'cannot': 858,\n",
       " 'was_so': 859,\n",
       " 'episode': 860,\n",
       " 'special_effects': 861,\n",
       " 'and_in': 862,\n",
       " 'obvious': 863,\n",
       " 'is_about': 864,\n",
       " 'it_all': 865,\n",
       " 'what_i': 866,\n",
       " 'and_even': 867,\n",
       " 'if_it': 868,\n",
       " 'dont_know': 869,\n",
       " 'hour': 870,\n",
       " 'save': 871,\n",
       " 'ago': 872,\n",
       " 'particularly': 873,\n",
       " 'across': 874,\n",
       " 'moment': 875,\n",
       " 'stop': 876,\n",
       " 'attempt': 877,\n",
       " 'strong': 878,\n",
       " 'mr': 879,\n",
       " 'characters_are': 880,\n",
       " 'cinematography': 881,\n",
       " 'saw_this': 882,\n",
       " 'exactly': 883,\n",
       " 'hand': 884,\n",
       " 'hilarious': 885,\n",
       " 'instead_of': 886,\n",
       " 'roles': 887,\n",
       " 'happen': 888,\n",
       " 'of_its': 889,\n",
       " 'try_to': 890,\n",
       " 'have_the': 891,\n",
       " 'living': 892,\n",
       " 'score': 893,\n",
       " 'even_the': 894,\n",
       " 'happened': 895,\n",
       " 'simple': 896,\n",
       " 'watching_this': 897,\n",
       " 'type': 898,\n",
       " 'it_in': 899,\n",
       " 'interest': 900,\n",
       " 'who_has': 901,\n",
       " 'a_real': 902,\n",
       " 'people_who': 903,\n",
       " 'movie_but': 904,\n",
       " 'girls': 905,\n",
       " 'each_other': 906,\n",
       " 'known': 907,\n",
       " 'wanted_to': 908,\n",
       " 'serious': 909,\n",
       " 'opening': 910,\n",
       " 'played_by': 911,\n",
       " 'usually': 912,\n",
       " 'the_beginning': 913,\n",
       " 'tries_to': 914,\n",
       " 'the_music': 915,\n",
       " 'huge': 916,\n",
       " 'saying': 917,\n",
       " 'car': 918,\n",
       " 'art': 919,\n",
       " 'out_to': 920,\n",
       " 'shown': 921,\n",
       " 'michael': 922,\n",
       " 'but_not': 923,\n",
       " 'been_a': 924,\n",
       " 'none': 925,\n",
       " 'taking': 926,\n",
       " 'i_watched': 927,\n",
       " 'with_her': 928,\n",
       " 'time_and': 929,\n",
       " 'of_these': 930,\n",
       " 'what_is': 931,\n",
       " 'etc': 932,\n",
       " 'wish': 933,\n",
       " 'as_if': 934,\n",
       " 'kid': 935,\n",
       " 'town': 936,\n",
       " 'possible': 937,\n",
       " 'released': 938,\n",
       " 'alone': 939,\n",
       " 'slow': 940,\n",
       " 'fight': 941,\n",
       " 'order': 942,\n",
       " 'somewhat': 943,\n",
       " 'child': 944,\n",
       " 'get_a': 945,\n",
       " 'or_the': 946,\n",
       " 'with_an': 947,\n",
       " 'running': 948,\n",
       " 'yourself': 949,\n",
       " 'get_the': 950,\n",
       " 'call': 951,\n",
       " 'talent': 952,\n",
       " 'the_show': 953,\n",
       " 'hit': 954,\n",
       " 'i_love': 955,\n",
       " 'started': 956,\n",
       " 'couple_of': 957,\n",
       " 'beyond': 958,\n",
       " 'could_be': 959,\n",
       " 'the_very': 960,\n",
       " 'off_the': 961,\n",
       " 'a_man': 962,\n",
       " 'mostly': 963,\n",
       " 'son': 964,\n",
       " 'sense_of': 965,\n",
       " 'even_though': 966,\n",
       " 'what_a': 967,\n",
       " 'to_give': 968,\n",
       " 'lets': 969,\n",
       " 'cool': 970,\n",
       " 'im_not': 971,\n",
       " 'way_to': 972,\n",
       " 'that_are': 973,\n",
       " 'seriously': 974,\n",
       " 'as_he': 975,\n",
       " 'anyway': 976,\n",
       " 'sad': 977,\n",
       " 'whose': 978,\n",
       " 'up_in': 979,\n",
       " 'between_the': 980,\n",
       " 'turned': 981,\n",
       " 'hours': 982,\n",
       " 'and_there': 983,\n",
       " 'ends': 984,\n",
       " 'opinion': 985,\n",
       " 'city': 986,\n",
       " 'up_the': 987,\n",
       " 'stories': 988,\n",
       " 'violence': 989,\n",
       " 'ok': 990,\n",
       " 'change': 991,\n",
       " 'ridiculous': 992,\n",
       " 'usual': 993,\n",
       " 'his_own': 994,\n",
       " 'knew': 995,\n",
       " 'was_in': 996,\n",
       " 'a_young': 997,\n",
       " 'think_that': 998,\n",
       " 'need_to': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
